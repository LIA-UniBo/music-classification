{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "\n",
    "import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from src.dataset import prepare_ds, add_audio_column\n",
    "from src.train import get_evaluator, get_model\n",
    "from src.utils import get_csv_name, get_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RES_DIR_PATH = \"res\"\n",
    "NOTEBOOK_ENV = \"jupyter\"\n",
    "\n",
    "AUDIOS_DIR_PATH = os.path.join(RES_DIR_PATH, \"mp3_data\")\n",
    "MODELS_DIR_PATH = os.path.join(RES_DIR_PATH, \"models\")\n",
    "DATASETS_DIR_PATH = os.path.join(RES_DIR_PATH, \"datasets\")\n",
    "CSV_PATH = os.path.join(RES_DIR_PATH, \"samples_clustered.csv\")\n",
    "\n",
    "TOP_N_GENRES = 6\n",
    "TOP_N_FEATURES = 9\n",
    "\n",
    "FEATURES_CONFIGS = {\n",
    "    \"subset\": {\"genre\": {\"top_n\": 3, \"samples\": 1000}},\n",
    "    \"genre\": {\"genre\": {\"top_n\": TOP_N_GENRES, \"samples\": None}},\n",
    "    \"category\": {\"category\": {\"top_n\": TOP_N_FEATURES, \"samples\": None}},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_CONFIG = {\n",
    "    \"epochs\": 20,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"warmup\": 0.0,\n",
    "    \"train_batch_size\": 8,\n",
    "    \"eval_batch_size\": 16,\n",
    "    \"feature_encoder\": None,\n",
    "    \"freeze_encoder\": None,\n",
    "    \"classifier_layers\": None, \n",
    "    \"classifier_dropout\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the filename indicating the subset of the whole dataset with the specific configurations\n",
    "\n",
    "dfs = {}\n",
    "for d in [\"subset\", \"category\", \"genre\"]:\n",
    "    filtered_csv_path = get_csv_name(FEATURES_CONFIGS[d], CSV_PATH)\n",
    "    dfs[d] = pd.read_csv(filtered_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function for loading the dataset for the requested model\n",
    "\n",
    "def load_and_prepare_ds(training_config, feature_config, df, clustered=True):\n",
    "    encoded_dataset_path = os.path.join(DATASETS_DIR_PATH, f\"ds-{training_config['feature_encoder']}-full-encoded\")\n",
    "    ds = datasets.load_from_disk(encoded_dataset_path)\n",
    "    ds = add_audio_column(ds, audios_dir_path=AUDIOS_DIR_PATH, training_config={\"feature_encoder\": training_config['feature_encoder']})\n",
    "    return prepare_ds(ds, df, feature_config, clustered=clustered, fixed_mapping=None, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = {\n",
    "    \"feature_encoder\": [\"wav2vec2\", \"whisper\"],\n",
    "    \"freeze_encoder\": [True, False],\n",
    "    \"classifier_layers\": [[256], [256, 256]],\n",
    "    \"dataset\": [\"subset\", \"genre\", \"category\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for every network in every split of the dataset\n",
    "stats = {}\n",
    "ds_type = None\n",
    "ds_encoder = None\n",
    "prepared_ds = None\n",
    "\n",
    "for conf in itertools.product(*combinations.values()):\n",
    "    TRAINING_CONFIG[\"feature_encoder\"] = conf[0]\n",
    "    TRAINING_CONFIG[\"freeze_encoder\"] = conf[1]\n",
    "    TRAINING_CONFIG[\"classifier_layers\"] = conf[2]\n",
    "    dataset = conf[3]\n",
    "\n",
    "    model_name = get_model_name(TRAINING_CONFIG)\n",
    "    model_path = os.path.join(MODELS_DIR_PATH, model_name)\n",
    "    TRAINING_CONFIG[\"model_path\"] = model_path\n",
    "    \n",
    "    if ds_encoder != TRAINING_CONFIG[\"feature_encoder\"] or ds_type != dataset:\n",
    "        ds_encoder = TRAINING_CONFIG[\"feature_encoder\"]\n",
    "        ds_type = dataset\n",
    "        prepared_ds = load_and_prepare_ds(TRAINING_CONFIG, FEATURES_CONFIGS[dataset], dfs[dataset])\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Loading {model_path} weights\")\n",
    "        \n",
    "        stats[model_name] = {}\n",
    "        model = get_model(TRAINING_CONFIG, prepared_ds[\"train\"])\n",
    "        trainer = get_evaluator(\n",
    "            model=model,\n",
    "            training_config=TRAINING_CONFIG,\n",
    "        )\n",
    "\n",
    "        for split in [\"train\", \"valid\", \"test\"]:\n",
    "            outputs = trainer.evaluate(prepared_ds[split])\n",
    "            \n",
    "            preds_label = np.array([model.config.id2label[idx] for idx in outputs.label_ids])\n",
    "\n",
    "            stats[model_name][split] = {\n",
    "                \"loss\": outputs.metrics[\"eval_loss\"],\n",
    "                \"acc\": outputs.metrics[\"eval_accuracy\"],\n",
    "                \"preds_id\": outputs.label_ids,\n",
    "                \"preds_label\": preds_label,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampled Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model    | Fine-tuned   | Classifier   | Split   |   Accuracy |   Loss |\n",
    "|:---------|:-------------|:-------------|:--------|-----------:|-------:|\n",
    "| wav2vec2 | No           | c256         | train   |     0.5432 | 0.9376 |\n",
    "| wav2vec2 | Yes          | c256         | train   |     0.9437 | 0.232  |\n",
    "| wav2vec2 | Yes          | c256_256     | train   |     0.4781 | 0.9955 |\n",
    "| whisper  | No           | c256         | train   |     0.5607 | 1.0336 |\n",
    "| whisper  | Yes          | c256         | train   |     0.9962 | 0.0194 |\n",
    "| whisper  | Yes          | c256_256     | train   |     0.9975 | 0.0169 |\n",
    "| wav2vec2 | No           | c256         | valid   |     0.54   | 0.9379 |\n",
    "| wav2vec2 | Yes          | c256         | valid   |     0.86   | 0.5778 |\n",
    "| wav2vec2 | Yes          | c256_256     | valid   |     0.55   | 0.9236 |\n",
    "| whisper  | No           | c256         | valid   |     0.58   | 1.0245 |\n",
    "| whisper  | Yes          | c256         | valid   |     0.84   | 1.0213 |\n",
    "| whisper  | Yes          | c256_256     | valid   |     0.89   | 0.6018 |\n",
    "| wav2vec2 | No           | c256         | test    |     0.54   | 0.9182 |\n",
    "| wav2vec2 | Yes          | c256         | test    |     0.76   | 0.9124 |\n",
    "| wav2vec2 | Yes          | c256_256     | test    |     0.46   | 0.9201 |\n",
    "| whisper  | No           | c256         | test    |     0.63   | 1.0249 |\n",
    "| whisper  | Yes          | c256         | test    |     0.85   | 0.9321 |\n",
    "| whisper  | Yes          | c256_256     | test    |     0.81   | 1.244  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model   | Fine-tuned   | Classifier   | Split   |   Accuracy |   Loss |\n",
    "|:--------|:-------------|:-------------|:--------|-----------:|-------:|\n",
    "| whisper | Yes          | c256         | train   |     0.9458 | 0.194  |\n",
    "| whisper | Yes          | c256         | valid   |     0.8393 | 0.5841 |\n",
    "| whisper | Yes          | c256         | test    |     0.83   | 0.646  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model   | Fine-tuned   | Classifier   | Split   |   Accuracy |   Loss |\n",
    "|:--------|:-------------|:-------------|:--------|-----------:|-------:|\n",
    "| whisper | Yes          | c256         | train   |     0.9774 | 0.0938 |\n",
    "| whisper | Yes          | c256         | valid   |     0.9251 | 0.3386 |\n",
    "| whisper | Yes          | c256         | test    |     0.9185 | 0.3587 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The encoding backbone is a major factor - Whisper achieves better results with less computational time\n",
    "- Fine-tuning the models is key for results - Since the pretrained model where based on speech, some training for the encoders on music audios can greatly improve performances \n",
    "- Different classification heads don't seem to affect the training much\n",
    "- Classification on `category` converged much faster than `genre` - This might be because of the ambiguous nature of genres, which may be very clearly identifiable in some edge cases, but almost impossible in some situations\n",
    "\n",
    "## Potential Improvements\n",
    "\n",
    "- Different preprocessing of the dataset: `genre` and `category` were grouped arbitrarily and could\n",
    "- More hyperparameter tuning: \n",
    "    - A deeper classification head might bring better performances to frozen backbones architetures\n",
    "- Heavier regularization: the only source of regularization performed in this work is early stopping\n",
    "- Other Transformer encoders for text-to-speech may be tried out"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "729786e4ac820b34608f27d07ec4fb597776bcc1a9d4d98bff8b4375359b1d17"
  },
  "kernelspec": {
   "display_name": "aii",
   "language": "python",
   "name": "aii"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
